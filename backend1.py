import os
import re
import sys
import json
import math
import types
import tempfile
import traceback
import subprocess

import vlm_code
import google.generativeai as genai
import time

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”§ mmaction2 drn ëª¨ë“ˆ ë²„ê·¸ íŒ¨ì¹˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def patch_mmaction_drn():
    try:
        drn_pkg = types.ModuleType("mmaction.models.localizers.drn")
        drn_drn = types.ModuleType("mmaction.models.localizers.drn.drn")
        class DRN: pass
        drn_drn.DRN = DRN
        drn_pkg.drn = drn_drn
        sys.modules["mmaction.models.localizers.drn"] = drn_pkg
        sys.modules["mmaction.models.localizers.drn.drn"] = drn_drn
        print("âœ… mmaction drn ëª¨ë“ˆ íŒ¨ì¹˜ ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸ drn íŒ¨ì¹˜ ì‹¤íŒ¨: {e}")

patch_mmaction_drn()

import torch
import pandas as pd
from flask import Flask, request, jsonify, Response
from flask_cors import CORS

from mmaction.apis import init_recognizer, inference_recognizer
from mmengine.config import Config

app = Flask(__name__)
CORS(app)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“‚ ê²½ë¡œ ì„¤ì •
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“‚ ê²½ë¡œ ë° ëª¨ë¸ ì„¤ì • (ìˆ˜ì •ë¨)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“‚ ê²½ë¡œ ë° ëª¨ë¸ ì„¤ì •
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
BASE_DIR = "/home/ubuntu/ai-muncheol"

MODEL_META = {
    1: {"k": 5,  "out_key": "accident_place",              "prob_key": "probability", "map_key": "model1", "db_map": "place", "label": "ì¥ì†Œ"},
    2: {"k": 10, "out_key": "accident_place_feature_code", "prob_key": "probability", "map_key": "model2", "db_map": "type",  "label": "ì‚¬ê³ ìœ í˜•"},
    3: {"k": 10, "out_key": "vehicle_a_code",              "prob_key": "prob",        "map_key": "model3", "db_map": "action", "label": "ì°¨ëŸ‰A"},
    4: {"k": 10, "out_key": "vehicle_b_code",              "prob_key": "prob",        "map_key": "model4", "db_map": "action", "label": "ì°¨ëŸ‰B"},
}

GROUPS = {
    "ì€ì„": "es",
    "í˜•ì„ ": "hs"
}

MODELS_CONFIG = {}
for name_kr, prefix in GROUPS.items():
    for i in range(1, 5):
        key = f"{prefix}_model{i}"
        meta = MODEL_META[i]
        
        MODELS_CONFIG[key] = {
            "config": os.path.join(BASE_DIR, f"{key}_config.py"),
            "checkpoint": os.path.join(BASE_DIR, f"{key}.pth"),
            "meta": meta,
            "group": name_kr
        }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ—ºï¸ ëª¨ë¸ ì¸ë±ìŠ¤ â†’ DB ID ë§¤í•‘
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MAP_MODEL1 = {i: v for i, v in enumerate([0, 1, 2, 3, 4, 5, 6, 13])}
MAP_MODEL2 = {i: v for i, v in enumerate([
    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 17, 18, 20, 21, 22, 23, 24,
    37, 38, 39, 40, 41, 45, 48, 49, 50, 59, 60
])}
MAP_MODEL3 = {i: v for i, v in enumerate([
    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20,
    21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 43, 44, 45,
    46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 88, 89,
    90, 91, 133, 134, 135, 138, 139, 140, 144, 147, 148, 154, 169, 170, 171,
    172, 173, 174, 175, 176, 177, 178, 179
])}
MAP_MODEL4 = {i: v for i, v in enumerate([
    0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21,
    23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 45, 46, 47, 50,
    52, 53, 54, 55, 56, 57, 58, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 74,
    87, 88, 89, 90, 91, 92, 139, 140, 142, 143, 146, 147, 150, 151, 165, 166,
    167, 168, 169, 170, 171, 172, 173
])}

MODEL_MAPS = {
    "model1": MAP_MODEL1,
    "model2": MAP_MODEL2,
    "model3": MAP_MODEL3,
    "model4": MAP_MODEL4,
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“Š ë¼ë²¨ ë§µ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
LABEL_MAP_PLACE = {
    0: "ì§ì„  ë„ë¡œ", 1: "ì‹ í˜¸ ì—†ëŠ” êµì°¨ë¡œ", 2: "ì‹ í˜¸ ìˆëŠ” êµì°¨ë¡œ",
    3: "tìí˜• ë„ë¡œ", 4: "ê¸°íƒ€ ë„ë¡œ", 5: "ì£¼ì°¨ì¥",
    6: "íšŒì „ êµì°¨ë¡œ", 13: "ê³ ì†ë„ë¡œ"
}

LABEL_MAP_TYPE = {}
LABEL_MAP_ACTION = {}
CRASH_DF = pd.DataFrame()

def load_csv_labels():
    global CRASH_DF, LABEL_MAP_TYPE, LABEL_MAP_ACTION

    csv_candidates = [
        os.path.join(BASE_DIR, "matching.csv"),
    ]

    df = pd.DataFrame()
    final_path = None

    for p in csv_candidates:
        if not os.path.exists(p):
            continue
        for enc in ["utf-8-sig", "utf-8", "cp949", "euc-kr"]:
            try:
                temp = pd.read_csv(p, encoding=enc)
                temp.columns = temp.columns.str.strip()
                if "ê³¼ì‹¤ë¹„ìœ¨A" in temp.columns and "ì‚¬ê³ ì¥ì†ŒíŠ¹ì§•_ID" in temp.columns:
                    df = temp
                    final_path = p
                    break
            except Exception:
                continue
        if not df.empty:
            break

    if df.empty:
        print("âš ï¸ 'ê³¼ì‹¤ë¹„ìœ¨A' ì»¬ëŸ¼ì´ í¬í•¨ëœ ìœ íš¨í•œ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    for col in ["ì‚¬ê³ ì¥ì†ŒíŠ¹ì§•_ID", "Aì§„í–‰ë°©í–¥_ID", "Bì§„í–‰ë°©í–¥_ID"]:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce").fillna(-1).astype(int)

    CRASH_DF = df

    if "ì‚¬ê³ ì¥ì†ŒíŠ¹ì§•_ID" in df.columns and "ì‚¬ê³ ì¥ì†ŒíŠ¹ì§•" in df.columns:
        LABEL_MAP_TYPE = df.groupby("ì‚¬ê³ ì¥ì†ŒíŠ¹ì§•_ID")["ì‚¬ê³ ì¥ì†ŒíŠ¹ì§•"].first().to_dict()

    if "Aì§„í–‰ë°©í–¥_ID" in df.columns:
        map_a = df[["Aì§„í–‰ë°©í–¥_ID", "Aì§„í–‰ë°©í–¥"]].dropna().drop_duplicates()
        map_b = df[["Bì§„í–‰ë°©í–¥_ID", "Bì§„í–‰ë°©í–¥"]].dropna().drop_duplicates()
        map_a.columns = ["ID", "Label"]
        map_b.columns = ["ID", "Label"]
        combined = pd.concat([map_a, map_b]).drop_duplicates(subset="ID")
        LABEL_MAP_ACTION = combined.set_index("ID")["Label"].to_dict()

    print(f"âœ… CSV ë¡œë“œ ì™„ë£Œ ({os.path.basename(final_path)}): {len(df)}í–‰, ì‚¬ê³ ìœ í˜• {len(LABEL_MAP_TYPE)}ê°œ, ì§„í–‰ë°©í–¥ {len(LABEL_MAP_ACTION)}ê°œ")

LABEL_MAPS = {
    "place": LABEL_MAP_PLACE,
    "type": LABEL_MAP_TYPE,
    "action": LABEL_MAP_ACTION,
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”§ Config ë¡œë“œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def safe_load_config(config_path):
    with open(config_path, "r", encoding="utf-8") as f:
        text = f.read()
    
    # 1. ì»¤ìŠ¤í…€ ì„í¬íŠ¸ êµ¬ë¬¸ ì œê±°
    text = re.sub(r"custom_imports\s*=\s*dict\(.*?\)\s*\n", "", text, flags=re.DOTALL)
    
    # 2. ğŸš¨ í•µì‹¬ ìˆ˜ì •: LDAMLossCustom -> CrossEntropyLoss ë¡œ ê°•ì œ ë³€í™˜
    if "LDAMLossCustom" in text:
        print(f" ğŸ› ï¸ [Config íŒ¨ì¹˜] {os.path.basename(config_path)}: LDAMLossCustom ì œê±° ì¤‘...")
        # íƒ€ì… ë³€ê²½
        text = text.replace("'LDAMLossCustom'", "'CrossEntropyLoss'")
        text = text.replace('"LDAMLossCustom"', '"CrossEntropyLoss"')
        
        # LDAM ì „ìš© íŒŒë¼ë¯¸í„°(ë¦¬ìŠ¤íŠ¸) ì œê±°
        text = re.sub(r"cls_num_list\s*=\s*\[.*?\]\s*,?", "", text, flags=re.DOTALL)
        
        # ğŸ”¥ [ìˆ˜ì •ë¨] LDAM ê¸°íƒ€ íŒŒë¼ë¯¸í„° ì œê±° (max_m, s)
        # \b (ë‹¨ì–´ ê²½ê³„)ë¥¼ ì¶”ê°€í•˜ì—¬ 'eps' ê°™ì€ ë‹¤ë¥¸ ë³€ìˆ˜ê°€ ë§ê°€ì§€ì§€ ì•Šë„ë¡ ë³´í˜¸í•¨
        text = re.sub(r"\bmax_m\s*=\s*[\d\.]+\s*,?", "", text)
        text = re.sub(r"\bs\s*=\s*[\d\.]+\s*,?", "", text)
        
    # 3. ê¸°ì¡´ FocalLoss ì²˜ë¦¬ (ìœ ì§€)
    text = re.sub(
        r"loss_cls=dict\(\s*alpha=[\s\S]*?type='mmdet\.FocalLoss'[\s\S]*?\)",
        "loss_cls=dict(type='CrossEntropyLoss', loss_weight=1.0)",
        text,
    )
    
    # 4. load_from ê²½ë¡œ ì œê±°
    text = re.sub(r"load_from\s*=\s*'[^']*'", "load_from = None", text)

    # ì„ì‹œ íŒŒì¼ ìƒì„± ë° ë¡œë“œ
    with tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False, encoding="utf-8") as tmp:
        tmp.write(text)
        tmp_path = tmp.name
    
    try:
        cfg = Config.fromfile(tmp_path)
    finally:
        if os.path.exists(tmp_path):
            os.remove(tmp_path)
            
    return cfg


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¬ ì˜ìƒ ì½”ë± í™•ì¸ / ë³€í™˜ (ffmpeg)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def get_video_codec(video_path):
    """ì˜ìƒ ì½”ë± í™•ì¸"""
    try:
        result = subprocess.run(
            ['ffprobe', '-v', 'error', '-select_streams', 'v:0',
             '-show_entries', 'stream=codec_name',
             '-of', 'default=noprint_wrappers=1:nokey=1', video_path],
            capture_output=True, text=True, timeout=10
        )
        return result.stdout.strip()
    except Exception:
        return "unknown"


def get_video_duration(video_path):
    """ì˜ìƒ ê¸¸ì´(ì´ˆ) ë°˜í™˜"""
    try:
        result = subprocess.run(
            ['ffprobe', '-v', 'error', '-show_entries', 'format=duration',
             '-of', 'default=noprint_wrappers=1:nokey=1', video_path],
            capture_output=True, text=True, timeout=10
        )
        return float(result.stdout.strip())
    except Exception:
        return None


def convert_to_h264(input_path, output_path):
    """H.264ë¡œ ë³€í™˜"""
    try:
        command = [
            'ffmpeg', '-y', '-i', input_path,
            '-vcodec', 'libx264',
            '-preset', 'ultrafast',
            '-crf', '23',
            '-acodec', 'aac', '-strict', '-2',
            output_path
        ]
        subprocess.run(command, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, timeout=120)
        return True
    except Exception as e:
        print(f"  âš ï¸ H.264 ë³€í™˜ ì‹¤íŒ¨: {e}")
        return False


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§  Top-K ì¶”ì¶œ (mmaction2 1.2.0 í˜¸í™˜)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def extract_top_k(res, model_name="", k=3):
    if isinstance(res, (list, tuple)):
        res = res[0]

    scores = None
    attrs = [a for a in dir(res) if not a.startswith('_')]

    # ë°©ë²• 1: pred_score
    if hasattr(res, 'pred_score') and scores is None:
        val = getattr(res, 'pred_score')
        if torch.is_tensor(val):
            scores = val

    # ë°©ë²• 2: pred_scores â†’ LabelData
    if hasattr(res, 'pred_scores') and scores is None:
        pred_scores = getattr(res, 'pred_scores')
        if torch.is_tensor(pred_scores):
            scores = pred_scores
        else:
            if hasattr(pred_scores, 'keys'):
                try:
                    for key in pred_scores.keys():
                        val = pred_scores[key]
                        if torch.is_tensor(val):
                            scores = val
                            break
                except Exception:
                    pass
            if scores is None and hasattr(pred_scores, 'values'):
                try:
                    for val in pred_scores.values():
                        if torch.is_tensor(val):
                            scores = val
                            break
                except Exception:
                    pass
            for attr in ['data', 'score', 'scores', 'label']:
                if scores is not None:
                    break
                if hasattr(pred_scores, attr):
                    val = getattr(pred_scores, attr)
                    if torch.is_tensor(val):
                        scores = val

    # ë°©ë²• 3: fallback
    if scores is None:
        for attr_name in attrs:
            if 'score' in attr_name.lower():
                val = getattr(res, attr_name, None)
                if torch.is_tensor(val) and val.dim() >= 1:
                    scores = val
                    break

    if scores is None:
        raise ValueError(f"[{model_name}] scores ì¶”ì¶œ ì‹¤íŒ¨!")

    if scores.dim() > 1:
        scores = scores.squeeze()
    scores = scores.cpu().to(torch.float64)

    print(f"  ğŸ“Š [{model_name}] scores shape: {scores.shape}")
    top5 = scores.topk(min(5, len(scores)))
    print(f"  ğŸ“Š [{model_name}] ìƒìœ„5 ê°’: {[f'{v:.4f}' for v in top5.values.tolist()]}")
    print(f"  ğŸ“Š [{model_name}] ìƒìœ„5 idx: {top5.indices.tolist()}")

    if scores.min() >= 0 and scores.max() <= 1 and scores.sum() > 0.5:
        probs = scores / scores.sum()
    else:
        probs = torch.nn.functional.softmax(scores, dim=0)

    topk_vals, topk_inds = torch.topk(probs, min(k, len(probs)))
    return topk_inds.tolist(), topk_vals.tolist()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸš€ ëª¨ë¸ ë¡œë“œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
loaded_models = {}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# âš–ï¸ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ (ìƒˆë¡œìš´ JSON êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •ë¨)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# âš–ï¸ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜ (í‚¤ ì´ë¦„ í˜¸í™˜ì„± ê°•í™”)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def calculate_fault_scores(group_data, crash_df):
    """
    group_data: final_output["ì€ì„"] ë˜ëŠ” final_output["í˜•ì„ "] ë¦¬ìŠ¤íŠ¸
    """
    if crash_df.empty or len(group_data) < 4:
        return None, []

    # ëª¨ë¸ 2, 3, 4 ê²°ê³¼ ë§¤í•‘ (ì¸ë±ìŠ¤: 1, 2, 3)
    cand_type = group_data[1] if group_data[1] else []
    cand_a = group_data[2] if group_data[2] else []
    cand_b = group_data[3] if group_data[3] else []

    eps = 1e-12
    combinations = []

    for t in cand_type:
        for a in cand_a:
            for b in cand_b:
                # 1. ì‚¬ê³ ìœ í˜• ì½”ë“œ ì¶”ì¶œ
                t_code = t.get("accident_place_feature_code")
                
                # 2. ì°¨ëŸ‰ A ì½”ë“œ ì¶”ì¶œ
                a_code = a.get("vehicle_a_code")
                
                # 3. ì°¨ëŸ‰ B ì½”ë“œ ì¶”ì¶œ (ì€ì„: vehicle_b_code, í˜•ì„ : vehicle_b_info_code í˜¸í™˜)
                b_code = b.get("vehicle_b_code", b.get("vehicle_b_info_code"))
                
                # í™•ë¥  ì¶”ì¶œ
                t_prob = t.get("probability", t.get("prob", 0))
                a_prob = a.get("probability", a.get("prob", 0))
                b_prob = b.get("probability", b.get("prob", 0))

                # í•„ìˆ˜ ì½”ë“œê°€ ì—†ìœ¼ë©´ ìŠ¤í‚µ
                if t_code is None or a_code is None or b_code is None:
                    continue

                log_score = (
                    math.log(max(float(t_prob), eps))
                    + math.log(max(float(a_prob), eps))
                    + math.log(max(float(b_prob), eps))
                )
                combinations.append({
                    "type": t_code, "a": a_code, "b": b_code,
                    "log_score": log_score,
                })

    if not combinations:
        return None, []

    # ì ìˆ˜ ì •ë ¬ ë° ìƒìœ„ í›„ë³´ ì¶”ì¶œ
    log_scores_tensor = torch.tensor([c["log_score"] for c in combinations], dtype=torch.float64)
    norm_confs = torch.nn.functional.softmax(log_scores_tensor, dim=0).tolist()

    for c, p in zip(combinations, norm_confs):
        c["norm_conf"] = p

    combinations.sort(key=lambda x: x["norm_conf"], reverse=True)

    fault_result = None
    alt_faults = []

    for combo in combinations:
        match_rows = crash_df[
            (crash_df["ì‚¬ê³ ì¥ì†ŒíŠ¹ì§•_ID"] == combo["type"])
            & (crash_df["Aì§„í–‰ë°©í–¥_ID"] == combo["a"])
            & (crash_df["Bì§„í–‰ë°©í–¥_ID"] == combo["b"])
        ]

        if not match_rows.empty:
            row = match_rows.iloc[0]
            fa = int(row["ê³¼ì‹¤ë¹„ìœ¨A"])
            fb = int(row["ê³¼ì‹¤ë¹„ìœ¨B"])

            entry = {
                "fa": fa,
                "fb": fb,
                "role_a": "ê°€í•´ì" if fa > fb else ("í”¼í•´ì" if fa < fb else "ìŒë°©"),
                "role_b": "í”¼í•´ì" if fa > fb else ("ê°€í•´ì" if fa < fb else "ìŒë°©"),
                "confidence": round(combo["norm_conf"] * 100, 2),
                "accident_place": str(row.get("ì‚¬ê³ ì¥ì†Œ", "")),
                "accident_feature": str(row.get("ì‚¬ê³ ì¥ì†ŒíŠ¹ì§•", "")),
                # ë””ë²„ê¹…ìš© ì •ë³´
                "codes": f"T{combo['type']}-A{combo['a']}-B{combo['b']}"
            }

            if fault_result is None:
                fault_result = entry
            elif len(alt_faults) < 3:
                alt_faults.append(entry)

            if len(alt_faults) >= 3 and fault_result is not None:
                break

    return fault_result, alt_faults



# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸŒ API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@app.route("/api/health", methods=["GET"])
def health():
    return jsonify({
        "status": "ok",
        "models_loaded": list(loaded_models.keys()),
        "device": "cuda" if torch.cuda.is_available() else "cpu",
        "label_map_type_count": len(LABEL_MAPS.get("type", {})),
        "label_map_action_count": len(LABEL_MAPS.get("action", {})),
        "csv_rows": len(CRASH_DF),
    })

@app.route("/api/convert", methods=["POST"])
def convert_preview():
    """ë¸Œë¼ìš°ì € ë¯¸ë¦¬ë³´ê¸°ìš© H.264 ë³€í™˜"""
    if "video" not in request.files:
        return jsonify({"error": "ì˜ìƒ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤"}), 400

    video_file = request.files["video"]
    suffix = os.path.splitext(video_file.filename)[1] or ".mp4"
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)
    video_file.save(tmp.name)
    tmp.close()
    input_path = tmp.name

    codec = get_video_codec(input_path)
    print(f"  ğŸ¬ [ë³€í™˜ ìš”ì²­] ì½”ë±: {codec}")

    if codec == "h264":
        # ì´ë¯¸ H.264ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
        from flask import send_file
        return send_file(input_path, mimetype="video/mp4", download_name="preview.mp4")

    output_path = input_path + "_h264.mp4"
    if convert_to_h264(input_path, output_path):
        os.remove(input_path)
        from flask import send_file
        resp = send_file(output_path, mimetype="video/mp4", download_name="preview.mp4")

        @resp.call_on_close
        def cleanup():
            try:
                os.remove(output_path)
            except Exception:
                pass

        return resp
    else:
        os.remove(input_path)
        return jsonify({"error": "ë³€í™˜ ì‹¤íŒ¨"}), 500
    

@app.route("/api/analyze", methods=["POST"])
def analyze():
    """8ê°œ ëª¨ë¸ ì‹¤í–‰ í›„ ê·¸ë£¹ë³„ JSON í¬ë§· ë°˜í™˜ ë° ê³¼ì‹¤ë¹„ìœ¨ ê³„ì‚°"""
    if "video" not in request.files:
        return jsonify({"error": "ì˜ìƒ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤"}), 400

    video_file = request.files["video"]
    suffix = os.path.splitext(video_file.filename)[1] or ".mp4"
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)
    video_file.save(tmp.name)
    tmp.close()
    video_path = tmp.name

    # ... (ì½”ë± ë³€í™˜ ë¡œì§ì€ ê¸°ì¡´ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€) ...
    # í¸ì˜ìƒ ì½”ë± ë³€í™˜ í›„ ì‹¤ì œ ì‚¬ìš©í•  ì˜ìƒ ê²½ë¡œë¥¼ actual_videoë¼ê³  ê°€ì •í•©ë‹ˆë‹¤.
    actual_video = video_path 
    # (í•„ìš”ì‹œ ìœ„ ì½”ë“œì˜ ë³€í™˜ ë¡œì§ ê·¸ëŒ€ë¡œ ì‚¬ìš©)

    def generate():
        try:
            # 1. ê²°ê³¼ ë‹´ì„ ê·¸ë¦‡ ì´ˆê¸°í™”
            final_output = {
                "ì€ì„": [[], [], [], []], # model 1, 2, 3, 4 ìˆœì„œëŒ€ë¡œ ì €ì¥
                "í˜•ì„ ": [[], [], [], []]
            }
            
            # ì§„í–‰ë¥  ê³„ì‚°ìš©
            total_models = len(MODELS_CONFIG)
            current_idx = 0

            # 2. ëª¨ë¸ ìˆœíšŒ (es_model1 -> es_model4 -> hs_model1 -> ...)
            # ìˆœì„œë¥¼ ë³´ì¥í•˜ê¸° ìœ„í•´ ì •ë ¬ (esê°€ ë¨¼ì € ì˜¤ë„ë¡)
            sorted_keys = sorted(MODELS_CONFIG.keys()) 

            for key in sorted_keys:
                cfg = MODELS_CONFIG[key]
                group_name = cfg.get("group", "ì€ì„")
                
                # 1. í‚¤ ì´ë¦„ì˜ ë§¨ ë ìˆ«ì(1~4)ë¥¼ ì¶”ì¶œí•´ ìë™ìœ¼ë¡œ ë°°ì—´ ì¸ë±ìŠ¤(0~3)ë¡œ ë³€í™˜
                model_num = int(key[-1])
                idx_in_group = model_num - 1
                
                # 2. ê¸°ì¡´ meta ë°©ì‹ê³¼ ì§ì ‘ í•˜ë“œì½”ë”© ë°©ì‹ ëª¨ë‘ í˜¸í™˜ë˜ë„ë¡ ì•ˆì „í•˜ê²Œ ê°’ ê°€ì ¸ì˜¤ê¸°
                meta = cfg.get("meta", cfg)
                k_val = meta.get("k", 10)
                out_key = meta.get("out_key", "code")
                prob_key = meta.get("prob_key", "prob")
                label_name = meta.get("label", f"ëª¨ë¸{model_num}")
                map_key = meta.get("map_key", f"model{model_num}")
                
                model = loaded_models.get(key)
                
                # ì§„í–‰ ìƒí™© ì „ì†¡
                msg_text = f"{group_name} {label_name} ë¶„ì„ ì¤‘..."
                yield f"data: {json.dumps({'type': 'progress', 'message': msg_text, 'percent': int(current_idx/total_models*90)}, ensure_ascii=False)}\n\n"

                if not model:
                    print(f"âŒ {key} ëª¨ë¸ ë¯¸ë¡œë“œ")
                    current_idx += 1
                    continue

                # 3. ì¶”ë¡  ì‹¤í–‰
                res = inference_recognizer(model, actual_video)
                
                # 4. Top-K ì¶”ì¶œ (ë™ì  K ì ìš©)
                inds, probs = extract_top_k(res, model_name=key, k=k_val)
                
                # ë§¤í•‘ í…Œì´ë¸” ê°€ì ¸ì˜¤ê¸°
                mapping = MODEL_MAPS.get(map_key, {})

                # 5. ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ìƒì„± (ê°ê° ë‹¤ë¥¸ í‚¤ ì´ë¦„ ì ìš©)
                model_result_list = []
                for idx, prob in zip(inds, probs):
                    code = mapping.get(idx, idx)
                    
                    item = {
                        out_key: int(code),
                        prob_key: float(prob)
                    }
                    model_result_list.append(item)

                # 6. ê²°ê³¼ ì €ì¥
                final_output[group_name][idx_in_group] = model_result_list
                current_idx += 1

            # -------------------------------------------------------------
            # [ì¶”ê°€ëœ ë¶€ë¶„] 8ê°œ ëª¨ë¸ ì¶”ë¡  ì™„ë£Œ í›„ ê³¼ì‹¤ë¹„ìœ¨ ë§¤ì¹­ (ì€ì„ ê¸°ì¤€)
            # -------------------------------------------------------------
            # ... (ì•ë¶€ë¶„ forë¬¸ ìƒëµ) ...

            # -------------------------------------------------------------
            # [ìˆ˜ì •ë¨] ê³¼ì‹¤ë¹„ìœ¨ ë§¤ì¹­: ì€ì„ / í˜•ì„  ê°ê° ìˆ˜í–‰
            # -------------------------------------------------------------
            
            # 1. ì€ì„ ëª¨ë¸ ê¸°ì¤€ ê³¼ì‹¤ë¹„ìœ¨
            fault_es, alt_es = calculate_fault_scores(final_output["ì€ì„"], CRASH_DF)
            
            # 2. í˜•ì„  ëª¨ë¸ ê¸°ì¤€ ê³¼ì‹¤ë¹„ìœ¨
            fault_hs, alt_hs = calculate_fault_scores(final_output["í˜•ì„ "], CRASH_DF)

            # ë¡œê·¸ ì¶œë ¥
            if fault_es:
                print(f"âš–ï¸ [ì€ì„] ê³¼ì‹¤ë¹„ìœ¨: A={fault_es['fa']}% / B={fault_es['fb']}%")
            else:
                print("âš ï¸ [ì€ì„] ê³¼ì‹¤ë¹„ìœ¨ ë§¤ì¹­ ì‹¤íŒ¨")

            if fault_hs:
                print(f"âš–ï¸ [í˜•ì„ ] ê³¼ì‹¤ë¹„ìœ¨: A={fault_hs['fa']}% / B={fault_hs['fb']}%")
            else:
                print("âš ï¸ [í˜•ì„ ] ê³¼ì‹¤ë¹„ìœ¨ ë§¤ì¹­ ì‹¤íŒ¨")

            # 3. ìµœì¢… ê²°ê³¼ ì „ì†¡ (êµ¬ì¡° ë³€ê²½)
            # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ fault_es, fault_hsë¥¼ ê°ê° ì¨ì•¼ í•©ë‹ˆë‹¤.
            final_evt = {
                "type": "complete",
                "input_data": final_output,
                
                # ê°ê°ì˜ ê²°ê³¼ ê°ì²´ë¥¼ ë‹´ì•„ ë³´ëƒ…ë‹ˆë‹¤
                "fault_results": {
                    "ì€ì„": {"best": fault_es, "alts": alt_es},
                    "í˜•ì„ ": {"best": fault_hs, "alts": alt_hs}
                },
                
                # (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€ìš©) ê¸°ì¡´ fault í‚¤ì—ëŠ” ì€ì„ ê²°ê³¼ë¥¼ ë„£ì–´ë‘ 
                "fault": fault_es, 
                "alt_faults": alt_es,
                
                "vlm_report": "VLM ë¶„ì„ì€ í˜„ì¬ ë¹„í™œì„±í™” ìƒíƒœì…ë‹ˆë‹¤." 
            }
            yield f"data: {json.dumps(final_evt, ensure_ascii=False)}\n\n"

        except Exception as e:
# ... (ë’·ë¶€ë¶„ ë™ì¼)
            traceback.print_exc()
            yield f"data: {json.dumps({'type': 'error', 'error': str(e)}, ensure_ascii=False)}\n\n"
        finally:
            if os.path.exists(video_path):
                os.remove(video_path)
            # ë³€í™˜ëœ íŒŒì¼ ì‚­ì œ ë¡œì§ ë“± ì¶”ê°€

    return Response(generate(), mimetype="text/event-stream")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸš€ ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜ (ì´ê²Œ ì—†ì–´ì„œ ì—ëŸ¬ê°€ ë‚œ ê²ë‹ˆë‹¤)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
loaded_models = {}

def load_all_models():
    global loaded_models
    device = "cuda:0" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ–¥ï¸  ë””ë°”ì´ìŠ¤: {device}")
    
    # MODELS_CONFIG í‚¤ ì •ë ¬ (ë¡œê·¸ ë³´ê¸° ì¢‹ê²Œ)
    sorted_keys = sorted(MODELS_CONFIG.keys())

    for key in sorted_keys:
        info = MODELS_CONFIG[key]
        config_path = info["config"]
        ckpt_path = info["checkpoint"]
        meta = info["meta"]
        
        if not os.path.exists(config_path):
            print(f"âŒ {key}: config ì—†ìŒ â†’ {config_path}")
            continue
        if not os.path.exists(ckpt_path):
            print(f"âŒ {key}: checkpoint ì—†ìŒ â†’ {ckpt_path}")
            continue
            
        try:
            print(f"ğŸ“¦ {key} ({meta['label']}) ë¡œë”© ì¤‘...")
            cfg = safe_load_config(config_path)
            
            # íŒŒì´í”„ë¼ì¸ ì„¤ì • ì•ˆì „ì¥ì¹˜
            if not hasattr(cfg, "test_pipeline") or cfg.test_pipeline is None:
                if hasattr(cfg, "val_pipeline"):
                    cfg.test_pipeline = cfg.val_pipeline
            
            model = init_recognizer(cfg, ckpt_path, device=device)
            loaded_models[key] = model
            print(f"âœ… {key} ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ {key} ë¡œë“œ ì‹¤íŒ¨: {e}")
            # traceback.print_exc() # í•„ìš”ì‹œ ì£¼ì„ í•´ì œ

    print(f"\nğŸ‰ ì´ {len(loaded_models)}/{len(MODELS_CONFIG)} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ ì„œë²„ ì‹œì‘
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if __name__ == "__main__":
    print("=" * 60)
    print("ğŸš€ AI ë¬¸ì²  ë°±ì—”ë“œ ì„œë²„ v4 (SSE + ffmpeg ë³€í™˜)")
    print("=" * 60)
    load_csv_labels()
    LABEL_MAPS["type"] = LABEL_MAP_TYPE
    LABEL_MAPS["action"] = LABEL_MAP_ACTION
    load_all_models()
    print("\n" + "=" * 60)
    print("ğŸŒ ì„œë²„ ì‹¤í–‰: http://localhost:5002")
    print("=" * 60 + "\n")
    app.run(host="0.0.0.0", port=5002, debug=False)